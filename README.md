# ğŸŒ Sistema Integrado de Captura y Scraping Web

Sistema automatizado para capturar screenshots y extraer datos de sitios web, incluyendo Facebook e Instagram, con generaciÃ³n automÃ¡tica de reportes en PDF y Word.

---

## ğŸ“‹ Tabla de Contenidos

- [Requisitos Previos](#-requisitos-previos)
- [InstalaciÃ³n Paso a Paso en Windows](#-instalaciÃ³n-paso-a-paso-en-windows)
- [ConfiguraciÃ³n](#-configuraciÃ³n)
- [EjecuciÃ³n del Proyecto](#-ejecuciÃ³n-del-proyecto)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [SoluciÃ³n de Problemas](#-soluciÃ³n-de-problemas)

---

## ğŸ”§ Requisitos Previos

Antes de comenzar, asegÃºrate de tener instalado:

1. **Node.js** (versiÃ³n 18 o superior)
2. **Python** (versiÃ³n 3.10 o superior)
3. **Git** (opcional, para clonar el repositorio)

---

## ğŸªŸ InstalaciÃ³n Paso a Paso en Windows

### **Paso 1: Instalar Node.js**

1. Descarga Node.js desde: https://nodejs.org/
2. Descarga la versiÃ³n **LTS** (Long Term Support)
3. Ejecuta el instalador y sigue las instrucciones
4. **Importante:** Marca la opciÃ³n "Add to PATH" durante la instalaciÃ³n

**Verificar instalaciÃ³n:**
```bash
node --version
npm --version
```

DeberÃ­as ver algo como:
```
v18.17.0
9.6.7
```

---

### **Paso 2: Instalar Python**

1. Descarga Python desde: https://www.python.org/downloads/
2. Descarga la versiÃ³n **3.10 o superior**
3. Ejecuta el instalador
4. **MUY IMPORTANTE:** âœ… Marca la casilla "Add Python to PATH"
5. Haz clic en "Install Now"

**Verificar instalaciÃ³n:**
```bash
python --version
pip --version
```

DeberÃ­as ver algo como:
```
Python 3.10.11
pip 23.2.1
```

---

### **Paso 3: Descargar el Proyecto**

**OpciÃ³n A - Con Git:**
```bash
git clone <url-del-repositorio>
cd capture-website-version
```

**OpciÃ³n B - Sin Git:**
1. Descarga el proyecto como ZIP
2. Extrae el archivo ZIP
3. Abre el CMD o PowerShell
4. Navega a la carpeta del proyecto:
```bash
cd ruta\donde\extraiste\capture-website-version
```

---

### **Paso 4: Instalar Dependencias de Node.js**

Dentro de la carpeta del proyecto, ejecuta:

```bash
npm install
```

Este proceso puede tardar **5-10 minutos** la primera vez. InstalarÃ¡:
- Playwright (navegador automatizado)
- LibrerÃ­as de generaciÃ³n de PDF
- LibrerÃ­as de procesamiento de imÃ¡genes
- Y mÃ¡s de 200 paquetes necesarios

**Espera el mensaje:**
```
âœ“ Packages installed successfully
```

---

### **Paso 5: Instalar Navegadores de Playwright**

Playwright necesita descargar navegadores especiales. Ejecuta:

```bash
npx playwright install chromium
```

Este comando descargarÃ¡ **~300 MB** de archivos.

**Espera el mensaje:**
```
âœ“ Chromium downloaded successfully
```

---

### **Paso 6: Crear Entorno Virtual de Python**

El proyecto usa scripts de Python para scraping. Crea un entorno virtual:

```bash
python -m venv venv_scraping
```

**Activar el entorno virtual:**

En **CMD**:
```bash
venv_scraping\Scripts\activate
```

En **PowerShell**:
```bash
venv_scraping\Scripts\Activate.ps1
```

**Nota:** Si PowerShell da error de permisos, ejecuta:
```bash
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

**DeberÃ­as ver** `(venv_scraping)` al inicio de tu lÃ­nea de comando.

---

### **Paso 7: Instalar Dependencias de Python**

Con el entorno virtual **activado**, instala las librerÃ­as necesarias:

```bash
pip install instaloader requests beautifulsoup4 facebook-scraper
```

**Espera el mensaje:**
```
Successfully installed...
```

**Desactivar el entorno virtual** (por ahora):
```bash
deactivate
```

---

## âš™ï¸ ConfiguraciÃ³n

### **Paso 8: Configurar Credenciales**

El sistema necesita credenciales para acceder a Facebook e Instagram.

**Edita el archivo:** `src/services/screenshotService.js`

Busca las lÃ­neas **13-24** y actualiza con tus credenciales:

```javascript
const FACEBOOK_CREDENTIALS = {
  username: "TU_USUARIO_FACEBOOK",  // Puede ser email o telÃ©fono
  password: "TU_CONTRASEÃ‘A_FACEBOOK"
};

const INSTAGRAM_CREDENTIALS = {
  username: "TU_USUARIO_INSTAGRAM",  // Email o nombre de usuario
  password: "TU_CONTRASEÃ‘A_INSTAGRAM"
};
```

**âš ï¸ IMPORTANTE:** 
- Usa credenciales de cuentas de prueba, NO tu cuenta personal
- Guarda este archivo de forma segura
- NO subas las credenciales a repositorios pÃºblicos

---

### **Paso 9: Preparar Archivos de URLs**

El sistema procesa URLs desde archivos de texto. Ya existen ejemplos:

**Archivos disponibles:**
- `1203_SITIOS_WEB_11_2024.txt` - Sitios web normales (HTTP)
- `2415 sitios web_dic_2024.txt` - MÃ¡s sitios web
- `289_perfiles_redes_sociales_10_12_2024_LIMPIO.txt` - Perfiles de redes sociales

**Para usar tu propio archivo:**

1. Crea un archivo `.txt` en la raÃ­z del proyecto
2. Agrega una URL por lÃ­nea:
   ```
   https://www.ejemplo.com
   https://www.facebook.com/pagina-ejemplo
   https://www.instagram.com/usuario-ejemplo
   ```

3. Edita `src/index_integrated.js` en la **lÃ­nea 203**:
   ```javascript
   const archivosUrls = [
     { archivo: 'TU_ARCHIVO.txt', protocolo: 'https' }
   ];
   ```

---

## ğŸš€ EjecuciÃ³n del Proyecto

### **Paso 10: Ejecutar el Sistema**

**Abre una terminal** (CMD o PowerShell) en la carpeta del proyecto y ejecuta:

```bash
node src/index_integrated.js
```

### **QuÃ© Esperar:**

El sistema harÃ¡ lo siguiente automÃ¡ticamente:

1. **ğŸ” AutenticaciÃ³n (2-3 minutos)**
   - IniciarÃ¡ sesiÃ³n en Facebook
   - IniciarÃ¡ sesiÃ³n en Instagram
   - **Se abrirÃ¡ un navegador visible** - NO lo cierres
   - EsperarÃ¡ 60 segundos para verificaciÃ³n manual si es necesario

2. **ğŸ“¸ Captura de Screenshots (variable)**
   - ProcesarÃ¡ cada URL
   - TomarÃ¡ screenshots con la barra del navegador visible
   - GuardarÃ¡ en la carpeta `screenshots/`
   - Progreso: `[X/TOTAL] Procesando: url...`

3. **ğŸ“Š GeneraciÃ³n de Reportes (1-2 minutos)**
   - CrearÃ¡ un PDF con todas las capturas
   - CrearÃ¡ un Word (.docx) con todas las capturas
   - GuardarÃ¡ en la carpeta `output/`

### **Resultados:**

Al finalizar, encontrarÃ¡s:

```
âœ… PDF generado: output/reporte-integrado-2025-XX-XX.pdf
âœ… Word generado: output/reporte-integrado-2025-XX-XX.docx
```

**Tiempo estimado:**
- 10 URLs: ~5 minutos
- 50 URLs: ~20 minutos
- 100 URLs: ~40 minutos
- 1000 URLs: ~6-8 horas

---

## ğŸ“ Estructura del Proyecto

```
capture-website-version/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ configuracion.js          # ConfiguraciÃ³n general
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ integratedScrapingService.js  # Servicio principal
â”‚   â”‚   â”œâ”€â”€ screenshotService.js      # Capturas de pantalla
â”‚   â”‚   â”œâ”€â”€ pdfGenerator.js           # GeneraciÃ³n de PDF
â”‚   â”‚   â””â”€â”€ wordGenerator.js          # GeneraciÃ³n de Word
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ urlLoader.js              # Carga de URLs
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ python/
â”‚   â”‚       â”œâ”€â”€ facebook_page_scraper_simple.py
â”‚   â”‚       â””â”€â”€ instagram_profile_scraper_simple.py
â”‚   â””â”€â”€ index_integrated.js           # ğŸ¯ Archivo principal
â”‚
â”œâ”€â”€ screenshots/                      # ğŸ“¸ Capturas generadas
â”œâ”€â”€ output/                           # ğŸ“„ PDFs y Word generados
â”œâ”€â”€ scraped_data/                     # ğŸ“Š Datos extraÃ­dos
â”œâ”€â”€ sesiones/                         # ğŸ” Sesiones guardadas
â”œâ”€â”€ venv_scraping/                    # ğŸ Entorno virtual Python
â”‚
â”œâ”€â”€ 1203_SITIOS_WEB_11_2024.txt      # ğŸ“ URLs de ejemplo
â”œâ”€â”€ package.json                      # Dependencias Node.js
â””â”€â”€ README.md                         # ğŸ“– Este archivo
```

---

## ğŸ› ï¸ SoluciÃ³n de Problemas

### **Problema: "node no se reconoce como comando"**

**SoluciÃ³n:**
1. Reinstala Node.js marcando "Add to PATH"
2. O agrega manualmente Node.js al PATH de Windows:
   - Panel de Control â†’ Sistema â†’ ConfiguraciÃ³n avanzada del sistema
   - Variables de entorno â†’ PATH
   - Agrega: `C:\Program Files\nodejs\`

---

### **Problema: "python no se reconoce como comando"**

**SoluciÃ³n:**
1. Reinstala Python marcando "Add Python to PATH"
2. O agrega manualmente Python al PATH:
   - Agrega: `C:\Users\TU_USUARIO\AppData\Local\Programs\Python\Python310\`

---

### **Problema: Error al activar venv en PowerShell**

**SoluciÃ³n:**
```bash
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

---

### **Problema: "Cannot find module 'chalk'"**

**SoluciÃ³n:**
```bash
npm install
```

---

### **Problema: Error de login en Facebook/Instagram**

**Posibles causas:**
1. Credenciales incorrectas
2. Cuenta bloqueada por intentos de login
3. VerificaciÃ³n de dos factores activada

**Soluciones:**
1. Verifica las credenciales en `src/services/screenshotService.js`
2. Usa una cuenta de prueba sin 2FA
3. Durante los 60 segundos de espera, resuelve captchas manualmente

---

### **Problema: El navegador se cierra inmediatamente**

**SoluciÃ³n:**
- Esto es normal si hay un error
- Revisa la consola para ver el mensaje de error
- Verifica que las credenciales sean correctas

---

### **Problema: "ECONNREFUSED" o errores de red**

**SoluciÃ³n:**
1. Verifica tu conexiÃ³n a Internet
2. Desactiva temporalmente firewall/antivirus
3. Algunas URLs pueden estar bloqueadas regionalmente

---

### **Problema: Proceso muy lento**

**Optimizaciones:**
1. Reduce el nÃºmero de URLs en tu archivo de prueba
2. Aumenta la concurrencia en `src/config/configuracion.js`:
   ```javascript
   concurrencia: 3  // Procesa 3 URLs simultÃ¡neamente
   ```
3. Cierra otros programas que consuman recursos

---

## ğŸ“Š CaracterÃ­sticas del Sistema

### **âœ… Capturas de Pantalla**
- Navegador real visible (con barra de direcciones)
- ResoluciÃ³n: 1920x1080
- Formato: PNG
- Detecta pÃ¡ginas bloqueadas/no disponibles
- Maneja errores 404, timeouts, etc.

### **âœ… Scraping de Datos**
- **Instagram:** Username, seguidores, biografÃ­a, posts
- **Facebook:** Nombre de pÃ¡gina, descripciÃ³n, posts
- Datos guardados en `scraped_data/`

### **âœ… Reportes Generados**
- **PDF:** Con capturas y anÃ¡lisis de disponibilidad
- **Word:** Mismo contenido en formato editable
- Incluye resumen ejecutivo
- Tabla de resultados
- InformaciÃ³n de conectividad

### **âœ… DetecciÃ³n Inteligente**
- PÃ¡ginas bloqueadas por Coljuegos (Colombia)
- Contenido privado vs bloqueado
- PÃ¡ginas no encontradas (404)
- Sitios offline

---

## ğŸ” Seguridad y Privacidad

1. **Credenciales:** Se almacenan localmente, NUNCA se envÃ­an a terceros
2. **Sesiones:** Se guardan en `sesiones/` para reutilizaciÃ³n
3. **Datos:** Todos los datos se procesan localmente
4. **Cookies:** Se almacenan en archivos JSON locales

---

## ğŸ†˜ Soporte

Si encuentras problemas:

1. **Revisa la consola** - Los errores se muestran con colores:
   - ğŸ”´ Rojo: Errores crÃ­ticos
   - ğŸŸ¡ Amarillo: Advertencias
   - ğŸŸ¢ Verde: Ã‰xito

2. **Verifica los logs** en la carpeta `output/`

3. **Archivos importantes para debug:**
   - `sesiones/facebook_cookies.json`
   - `sesiones/instagram_cookies.json`
   - Archivos en `scraped_data/`

---

## ğŸ“ Notas Importantes

- **Primera ejecuciÃ³n:** Puede tardar mÃ¡s por autenticaciÃ³n inicial
- **Sesiones persistentes:** Los logins se guardan para futuras ejecuciones
- **LÃ­mites de rate:** Instagram/Facebook pueden bloquear despuÃ©s de ~100 URLs
- **Pausas automÃ¡ticas:** El sistema hace pausas cada 40-50 capturas
- **Navegador visible:** NO cierres el navegador durante el proceso

---

## ğŸ¯ Comandos RÃ¡pidos

```bash
# Instalar todo
npm install
npx playwright install chromium
python -m venv venv_scraping
venv_scraping\Scripts\activate
pip install instaloader requests beautifulsoup4 facebook-scraper
deactivate

# Ejecutar
node src/index_integrated.js

# Ver resultados
cd output
dir
```

---


**Â¡Listo! ğŸ‰ Ahora puedes ejecutar el sistema en Windows sin problemas.**
