# ğŸ“˜ GuÃ­a: Script de Scraping Real con PDF

Esta guÃ­a explica cÃ³mo usar **`index_scraping_pdf.js`** para hacer scraping real de Facebook e Instagram y generar un PDF.

---

## ğŸ¯ Â¿QuÃ© Hace Este Script?

1. **Lee URLs** de un archivo de texto
2. **Hace scraping REAL** usando scripts de Python
3. **EvalÃºa contenido** (si la pÃ¡gina existe, tiene datos, etc.)
4. **Genera PDF** con anÃ¡lisis detallado
5. **Guarda JSON** con todos los datos extraÃ­dos

---

## ğŸš€ CÃ³mo Usarlo

### Paso 1: Preparar el Archivo de URLs

Crea un archivo de texto con URLs (una por lÃ­nea):

```bash
# OpciÃ³n A: Usar el archivo de ejemplo
nano urls-scraping-prueba.txt

# OpciÃ³n B: Usar tus archivos existentes
# Ya tienes: 289_perfiles_redes_sociales_10_12_2024.txt
```

**Formato del archivo:**
```
https://www.facebook.com/pagina1
https://www.facebook.com/pagina2
https://www.instagram.com/usuario1
https://www.instagram.com/usuario2
# Comentarios con # se ignoran
```

### Paso 2: Ejecutar el Script

**Con archivo por defecto (`test-scraping-urls.txt`):**
```bash
node src/index_scraping_pdf.js
```

**Con archivo personalizado:**
```bash
node src/index_scraping_pdf.js urls-scraping-prueba.txt
```

**Con tus archivos de redes sociales:**
```bash
node src/index_scraping_pdf.js 289_perfiles_redes_sociales_10_12_2024.txt
```

---

## ğŸ“Š Â¿QuÃ© URLs Procesa?

| Tipo | Â¿Hace Scraping? | Â¿QuÃ© Extrae? |
|------|-----------------|--------------|
| **Facebook** | âœ… SÃ­ | Nombre, descripciÃ³n, imagen de perfil, seguidores |
| **Instagram** | âœ… SÃ­ | Username, bio, followers, posts, imagen de perfil |
| **Otros sitios** | âŒ No | Los ignora |

---

## ğŸ“„ Archivos Generados

DespuÃ©s de ejecutar, obtendrÃ¡s:

1. **JSON con datos completos:**
   ```
   resultados-scraping-2025-10-06.json
   ```
   Contiene todos los datos extraÃ­dos de cada URL

2. **PDF con anÃ¡lisis:**
   ```
   output/reporte-scraping-2025-10-06.pdf
   ```
   Contiene evaluaciÃ³n visual de cada URL

---

## ğŸ” EvaluaciÃ³n de Contenido

El script determina si una URL tiene contenido usando **indicadores reales**:

### Facebook - Indicadores Positivos:
- âœ… PÃ¡gina existe
- âœ… Imagen de perfil descargada
- âœ… Tiene tÃ­tulo vÃ¡lido
- âœ… Tiene descripciÃ³n

### Facebook - Indicadores Negativos:
- âŒ PÃ¡gina no existe
- âŒ Requiere login
- âŒ Error al acceder

### Instagram - Indicadores Positivos:
- âœ… Usuario existe
- âœ… Imagen de perfil descargada
- âœ… Tiene seguidores > 0
- âœ… Tiene posts > 0

### Instagram - Indicadores Negativos:
- âŒ Usuario no existe
- âŒ Perfil privado sin acceso
- âŒ Login requerido

---

## âš™ï¸ Requisitos

Este script **necesita**:

1. âœ… Python con el entorno virtual activado
2. âœ… Scripts de Python en `src/scripts/python/`
3. âœ… Credenciales de Facebook/Instagram (si aplica)

**Verificar:**
```bash
# Ver si el entorno virtual existe
ls -la venv_scraping/

# Ver si los scripts de Python existen
ls -la src/scripts/python/
```

---

## ğŸ†š Diferencias con Otros Scripts

| Script | Â¿Hace Scraping? | Â¿Toma Capturas? | Velocidad | Uso |
|--------|-----------------|-----------------|-----------|-----|
| `index_scraping_pdf.js` | âœ… SÃ­ | âŒ No | ğŸ¢ Lento | AnÃ¡lisis profundo |
| `regenerar-pdf-rapido.js` | âŒ No | âŒ No | âš¡âš¡âš¡ Muy rÃ¡pido | Regenerar PDF |
| `index_integrated.js` | âœ… SÃ­ | âœ… SÃ­ | ğŸŒ Muy lento | Todo completo |

---

## ğŸ’¡ Casos de Uso

### Usar `index_scraping_pdf.js` cuando:
- âœ… Quieres validar si perfiles/pÃ¡ginas existen
- âœ… Necesitas extraer datos reales (followers, posts, etc.)
- âœ… Quieres evaluar contenido sin tomar capturas
- âœ… Tienes pocas URLs (< 100)

### NO usar cuando:
- âŒ Tienes mÃ¡s de 500 URLs (muy lento)
- âŒ Solo quieres capturas de pantalla
- âŒ Ya tienes capturas y solo necesitas PDF
- âŒ Necesitas procesar sitios web normales (no FB/IG)

---

## ğŸ“ Ejemplo Completo

```bash
# 1. Ir al directorio del proyecto
cd /home/yeralcode/Documentos/ITRC/PROJECT/screenshots-web-faceboock/capture-website-version

# 2. Crear archivo con URLs de prueba (ya estÃ¡ creado)
cat urls-scraping-prueba.txt

# 3. Ejecutar el script
node src/index_scraping_pdf.js urls-scraping-prueba.txt

# 4. Ver resultados
ls -lh resultados-scraping-*.json
ls -lh output/reporte-scraping-*.pdf
```

---

## ğŸ”§ SoluciÃ³n de Problemas

### Error: "No se encontrÃ³ el archivo de URLs"
**Causa:** El archivo no existe o estÃ¡ en otra ubicaciÃ³n

**SoluciÃ³n:**
```bash
# Verificar que el archivo existe
ls -la urls-scraping-prueba.txt

# Usar ruta completa si es necesario
node src/index_scraping_pdf.js /ruta/completa/al/archivo.txt
```

### Error: "Error ejecutando script de Python"
**Causa:** Entorno virtual no activado o falta dependencia

**SoluciÃ³n:**
```bash
# Activar entorno virtual
source venv_scraping/bin/activate

# Instalar dependencias si faltan
pip install instaloader playwright
```

### Scraping muy lento
**Causa:** Hay pausa de 2 segundos entre cada URL (lÃ­nea 202)

**SoluciÃ³n:**
- Para pocas URLs (< 50): Normal, deja que termine
- Para muchas URLs (> 100): Usa `regenerar-pdf-rapido.js` en su lugar

---

## ğŸ¯ RecomendaciÃ³n

**Para tus archivos grandes (1473 URLs):**

No uses `index_scraping_pdf.js` porque:
- TomarÃ­a ~50 minutos (2 seg Ã— 1473 URLs)
- Python puede fallar a mitad de camino
- Es innecesario si solo quieres el PDF

**En su lugar:**
```bash
# Usa el script rÃ¡pido que ya creamos
node regenerar-pdf-rapido.js
```

**Usa `index_scraping_pdf.js` solo para:**
- Validar 10-50 URLs especÃ­ficas
- Extraer datos detallados de perfiles importantes
- AnÃ¡lisis profundo de casos especÃ­ficos

---

## ğŸ“ Resumen RÃ¡pido

```bash
# PARA POCAS URLs CON SCRAPING REAL:
node src/index_scraping_pdf.js urls-scraping-prueba.txt

# PARA MUCHAS URLs SIN SCRAPING (RÃPIDO):
node regenerar-pdf-rapido.js

# PARA REGENERAR PDF SUPER RÃPIDO:
node regenerar-pdf-simple.js
```

Cada script tiene su propÃ³sito. Â¡Elige el correcto segÃºn tus necesidades!

